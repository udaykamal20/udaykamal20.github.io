---
---

@string{aps = {American Physical Society,}}

@inproceedings{anonymous2023associative,
  abbr={ICLR},
  title={Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception},
  author={Uday Kamal* and Saurabh Das* and Saibal Mukhopadhyay},
  abstract={We propose EventFormer, a computationally efficient event-based representation learning framework for asynchronously processing event camera data. EventFormer treats sparse input events as a spatially unordered set and models their spatial interactions using self-attention mechanism. An associative memory-augmented recurrent module is used to correlate with the stored representation computed from past events. A memory addressing mechanism is proposed to store and retrieve the latent states only where these events occur and update them only when they occur. The representation learning shift from input space to the latent memory space resulting in reduced computation cost for processing each event. We show that EventFormer achieves 0.5% and 9% better accuracy with 30000x and 200x less computation compared to the state-of-the-art dense and event-based method, respectively, on event-based object recognition datasets.},
  booktitle={ICLR,},
  year={2023},
  mention={ (notable-25%)},
  preview={eventformer.png},
  html={https://openreview.net/forum?id=ZCStthyW-TD},
  selected={true}
}

@article{kamal2022anatomy,
  title={Anatomy-xnet: An anatomy aware convolutional neural network for thoracic disease classification in chest x-rays},
  author={Kamal, Uday and Zunaed, Mohammad and Nizam, Nusrat Binta and Hasan, Taufiq},
  abstract={Thoracic disease detection from chest radiographs using deep learning methods has been an active area of research in the last decade. Most previous methods attempt to focus on the diseased organs of the image by identifying spatial regions responsible for significant contributions to the model's prediction. In contrast, expert radiologists first locate the prominent anatomical structures before determining if those regions are anomalous. Therefore, integrating anatomical knowledge within deep learning models could bring substantial improvement in automatic disease classification. Motivated by this, we propose Anatomy-XNet, an anatomy-aware attention-based thoracic disease classification network that prioritizes the spatial features guided by the pre-identified anatomy regions. We adopt a semi-supervised learning method by utilizing available small-scale organ-level annotations to locate the anatomy regions in large-scale datasets where the organ-level annotations are absent. The proposed Anatomy-XNet uses the pre-trained DenseNet-121 as the backbone network with two corresponding structured modules, the Anatomy Aware Attention (A 3 ) and Probabilistic Weighted Average Pooling, in a cohesive framework for anatomical attention learning. We experimentally show that our proposed method sets a new state-of-the-art benchmark by achieving an AUC score of 85.78%, 92.07%, and, 84.04% on three publicly available large-scale CXR datasets–NIH, Stanford CheXpert, and MIMIC-CXR, respectively. This not only proves the efficacy of utilizing the anatomy segmentation knowledge to improve the thoracic disease classification but also demonstrates the generalizability of the proposed framework.},
  journal={IEEE Journal of Biomedical and Health Informatics (JBHI),},
  volume={26},
  number={11},
  pages={5518--5528},
  year={2022},
  preview={anatomyx.png},
  html={https://ieeexplore.ieee.org/document/9860074},
  selected={true},
  publisher={IEEE}
}

@article{ahmed2021dfr,
  title={DFR-TSD: A deep learning based framework for robust traffic sign detection under challenging weather conditions},
  author={Ahmed, Sabbir and Kamal, Uday and Hasan, Md Kamrul},
  abstract={Robust traffic sign detection and recognition (TSDR) is of paramount importance for the successful realization of autonomous vehicle technology. The importance of this task has led to vast amount of research efforts and many promising methods have been proposed in the existing literature. However, most of these methods have been evaluated on clean and challenge-free datasets and overlooked the performance deterioration associated with different challenging conditions (CCs) that obscure the traffic-sign images captured in the wild. In this paper, we look at the TSDR problem under CCs and focus on the performance degradation associated with them. To this end, we propose a Convolutional Neural Network (CNN) based prior enhancement focused TSDR framework. Our modular approach consists of a CNN-based challenge classifier, Enhance-Net–an encoder-decoder CNN architecture for image enhancement, and two separate CNN architectures for sign-detection and classification. We propose a novel training pipeline for Enhance-Net that focuses on the enhancement of the traffic sign regions (instead of the whole image) in the challenging images subject to their accurate detection. We used CURE-TSD dataset consisting of traffic videos captured under different CCs to evaluate the efficacy of our approach. We experimentally show that our method obtains an overall precision and recall of 91.1% and 70.71% that is 7.58% and 35.90% improvement in precision and recall, respectively, compared to the current benchmark. Furthermore, we compare our approach with different CNN-based TSDR methods and show that our approach outperforms them by a large margin.},
  journal={IEEE Transactions on Intelligent Transportation Systems (T-ITS),},
  year={2021},
  preview={dfrtsd.png},
  selected={true},
  html={https://ieeexplore.ieee.org/abstract/document/9345465},
  publisher={IEEE}
}

@inproceedings{kamal2020lung,
  title={Lung cancer tumor region segmentation using recurrent 3d-denseunet},
  author={Kamal, Uday and Rafi, Abdul Muntakim and Hoque, Rakibul and Wu, Jonathan and Hasan, Md Kamrul},
  abstract={The performance of a computer-aided automated diagnosis system of lung cancer from Computed Tomography (CT) volumetric images greatly depends on the accurate detection and segmentation of tumor regions. In this paper, we present Recurrent 3D-DenseUNet, a novel deep learning based architecture for volumetric lung tumor segmentation from CT scans. The proposed architecture consists of a 3D encoder block that learns to extract fine-grained spatial and coarse-grained temporal features, a recurrent block of multiple Convolutional Long Short-Term Memory (ConvLSTM) layers to extract fine-grained spatio-temporal information, and finally a 3D decoder block to reconstruct the desired volume segmentation masks from the latent feature space. The encoder and decoder blocks consist of several 3D-convolutional layers that are densely connected among themselves so that necessary feature aggregation can occur throughout the network. During prediction, we apply selective thresholding followed by morphological operation, on top of the network prediction, to better differentiate between tumorous and non-tumorous image-slices, which shows more promise than only thresholding-based approaches. We train and test our network on the NSCLC-Radiomics dataset of 300 patients, provided by The Cancer Imaging Archive (TCIA) for the 2018 IEEE VIP Cup. Moreover, we perform an extensive ablation study of different loss functions in practice for this task. The proposed network outperforms other state-of-the-art 3D segmentation architectures with an average dice score of 0.7228.},
  booktitle={MICCAI Thoracic Image Analysis Workshop, },
  year={2020},
  preview={miccai.png},
  selected={true},
  html={https://ieeexplore.ieee.org/abstract/document/9345465},
}